import os
import time
import types
from scipy import stats
import tempfile
from collections import OrderedDict
from logging import getLogger
import pandas as pd
import shutil

from starkit.fitkit.samplers.priors import PriorCollection

logger = getLogger(__name__)

import json

import numpy as np


try:
    import pymultinest
except ImportError:
    multinest_available = False
    raise
else:
    multinest_available = True

def multinest_evaluate(self, model_param, ndim, nparam):
    # returns the likelihood of observing the data given the model param_names

    model_param = np.array([model_param[i] for i in xrange(np.sum(~self.fixed_mask()))])

    self.parameters[~self.fixed_mask()] = model_param


    loglikelihood = self()

    return loglikelihood

def fixed_mask(self):
    return np.array([getattr(self, param_name).fixed
                      for param_name in self.param_names])



class MultiNestResult(object):


    @classmethod
    def from_multinest_basename(cls, basename, parameter_names):
        """
        Reading a MultiNest result from a basename

        Parameters
        ----------

        basename: str
            basename (path + prefix) for a multinest run

        Returns
            : ~MultinestResult
        """

        posterior_data = cls.read_posterior_data(basename, parameter_names)

        return cls(posterior_data)

    @classmethod
    def from_hdf5(cls, h5_fname, key):
        """
        Reading a Multinest result from its generated HDF5 file

        Parameters
        ----------

        h5_fname: ~str
            HDF5 filename

        key: ~str
            group identifier in the store
        """

        posterior_data = pd.read_hdf(h5_fname, key)

        return cls(posterior_data)


    @staticmethod
    def read_posterior_data(basename, parameter_names):
        """
        Reading the posterior data into a pandas dataframe

        """

        posterior_data = pd.read_csv('{0}_.txt'.format(basename),
                           delim_whitespace=True,
                           names=['posterior', 'x'] + parameter_names)
        posterior_data.index = np.arange(len(posterior_data))
        return posterior_data

    def __init__(self, posterior_data):
        self.posterior_data = posterior_data
        self.parameter_names = [col_name for col_name in posterior_data.columns
                                if col_name not in ['x', 'posterior']]

    def calculate_sigmas(self, sigma):
        sigmas = OrderedDict()
        for parameter_name in self.parameter_names:
            posterior_data = self.posterior_data.sort(parameter_name)
            parameter_values, posterior_values = (posterior_data[parameter_name],
                                                  posterior_data['posterior'])
            posterior_cumsum = posterior_values.cumsum()

            norm_distr = stats.norm(loc=0.0, scale=1.)

            sigma_low = np.interp(norm_distr.cdf(-sigma), posterior_cumsum,
                                  parameter_values)

            sigma_high = np.interp(norm_distr.cdf(sigma), posterior_cumsum,
                                  parameter_values)


            sigmas[parameter_name] = (sigma_low, sigma_high)

        return sigmas

    @property
    def mean(self):
        if not hasattr(self, '_mean'):
            _mean = OrderedDict([(param_name,
                                  np.average(self.posterior_data[param_name],
                                             weights=
                                             self.posterior_data['posterior']))
                                 for param_name in self.parameter_names])
            self._mean = _mean

        return self._mean


    def plot_triangle(self, **kwargs):
        try:
            from triangle import corner
        except ImportError:
            raise ImportError('Plotting requires trianglepy')
        data_columns = self.posterior_data.columns[2:]
        corner(self.posterior_data[data_columns],
               weights=self.posterior_data.posterior, **kwargs)





class MultiNest(object):
    """
    Use multinest to fit a spectrum using a grid of models generated by specgrid.

    Parameters
    ----------


    likelihood: ~Likelihood object, optional
        By default uses the Likelihood object which uses the chi-square for the
        likelihood of observing the data given the model param_names

    run_dir:

    """


    def __init__(self, likelihood, priors, run_dir=None, prefix='specgrid_multinest'):

        self.run_dir = run_dir
        self.prefix = prefix
        self.likelihood = likelihood
        self.likelihood.multinest_evaluate = types.MethodType(
            multinest_evaluate, self.likelihood)

        self.likelihood.fixed_mask = types.MethodType(fixed_mask,
                                                      self.likelihood)
        if not hasattr(priors, 'prior_transform'):
            self.priors = PriorCollection(priors)
        else:
            self.priors = priors




    @property
    def n_params(self):
        return np.sum(~self.likelihood.fixed_mask())

    @property
    def basename_(self):
        return '{0}_'.format(self.basename)

    @property
    def posterior_data(self):
        if self._posterior_data is None:
            self._posterior_data = self.read_posterior_data()

        return self._posterior_data

    def prepare_fit_directory(self, run_dir, prefix):
        if not os.path.exists(run_dir):
            os.mkdir(run_dir)

        # checking if previous chains already exist
        return os.path.join(run_dir, prefix)

    def run(self, clean_up=None, **kwargs):

        if clean_up is None:
            if self.run_dir is None:
                clean_up = True
            else:
                clean_up = False


        if self.run_dir is None:
            run_dir = tempfile.mkdtemp()
        else:
            run_dir = self.run_dir

        basename = self.prepare_fit_directory(run_dir, self.prefix)


        start_time = time.time()

        logger.info('Starting fit in {0} with prefix {1}'.format(run_dir, self.prefix))
        pymultinest.run(self.likelihood.multinest_evaluate, self.priors.prior_transform,
                        self.n_params,
                        outputfiles_basename='{0}_'.format(basename),
                        **kwargs)

        logger.info("Fit finished - took {0:.2f} s"
                    .format(time.time() - start_time))
        fitted_parameter_names = [item for item in self.likelihood.param_names
                                  if not self.likelihood.fixed[item]]

        self.result = MultiNestResult.from_multinest_basename(
            basename, fitted_parameter_names)

        if clean_up == True:
            logger.info("Cleaning up - deleting {0}".format(run_dir))
            shutil.rmtree(run_dir)

        return self.result





    def __repr__(self):
        return "{0}\n\n{1}".format(
            self.likelihood, self.priors)